---
title: Configuring Autograders
---

To be written.

## Summary of Autograding Architecture

The solutions repo automatically contains an empty pawtograder.yml file. This file configures the autograder for the assignment using the "overlay grader". The "overlay grader" is broken into three separate units: the build configuration, the graded parts, and the submission files.

# Build config

The `build` property has a number of subproperties

- preset allows you to choose one of the avilalbe build presets. This is the only required property. Currently, there are three presets:
  - `java-gradle` for bulding Java projects that use Gradle
  - `python-script` for building Python projects with custom scripts
  - `none` for custom project setups
- cmd is the CLI command for running your testing infrastucture.
- artifacts allows you to add a bullet point list of artifacts to be generated by the build. TODO: Is this true?
- linter which allows you to specifiy how code style should be checked and the results of running that liner. This option contains two required suboptions
  - preset which is the linter you would like to use. Right now, "checkstyle" is available as the only preset option.
  - policy which has two options: 'ignore' or 'fail'.
    - 'fail' reports the results of the linter, but _prevents_ the student code from being run on autograder results. Setting this option means any linter error will result in a zero from the autograder.
    - 'ignore' reports the results of the linter, but allows the student submission to be run on the autograder and display those results.
- student_tests determines what to do with the student tests on both the student implementation under the student_impl property and the instructor implementation under the instructor_impl property. The student_impl property has a special sbuproperty, `report_branch_coverage` which reports the coverage of the student tests on their own implemenatiion. Otherwise, both subproperties contain the following optional properties:
  - run_tests: a boolean flag for whether student tests should be run on the implementation in question.
  - run_mutation: a boolean falg which runs the student tests under mutations of the implementation in question.
  - report_mutation_coverage which generates a student-visible report of mutation testing by mutating the implementation in question.
- timeouts_seconds for setting timeouts for a few parts of the autograder. These are each specified as subproperties.
  - `build`: timeout in seconds for the build process
  - `instructor_tests`: timeout in seconds for each instructor test
  - `student_tests`: timeout in seconds for each student test
  - `mutants`: timeout in seconds for each run in mutation testing
  
# Graded parts

Graded parts are hierarchcally structured as follows

- Grade Part Name
  - Grade Unit 1
  - Grade Unit 2
  - ...

The Graded units can either be regulart testing units like JUnit tests or they can be mutation test units.

- Regular graded units are composed of 5 parts
  - a name for the graded unit
  - the number of points allocated to that unit
  - the number of tests in that unit
  - A bullet point list of tests. For Java, these are fully quantified JUnit test methods. For Python, ????. The number of tests listed here must match the testCount declared earlier.

There is also an optional propert `allow_partial_credit`, a boolean flag that when set to true allows for partial credit for the grading unit. Partial credit is calcualted as `number of tests passed` / `testCount`. By default, partial credit is enabled. TODO: Is it enabled by default?

- Mutation testing units are composed of the following and all are required
  - a name for the graded unit
  - an array of locations, an array of strings reporting the locations of the mutants TODO: Is this true?
  - an array of breakpoints. Each breakpoint has two subproperties
    - minimumMutantsDetected: the minimum number of mutants some test should find
    - pointsToAward: the number of points awarded for finding the minimum number of mutants

# Submission files

In this section, you declare the files that are accepted by Pawtograder for manual grading and testing. These are split into two necessary subfields: _files_ and _testFiles_.

- _files_ are the source code and any auxilliary files you want to either autograde or manually grade.
- _test_files_ are the locations of test files you want to either autograder, report about, or manually grade.

Both are declared as bullet point lists with one expression per line. The expression describes a set of files. You can use globs much like in `grep` and `find` to collect subdirectories or files with specific extensions.

# Script Info

Some autograders need custom scripts to run. The schema allows for those scripts to be entered as part of the autograder.

TODO: Describe the properties of the ScriptInfo property and the Venv properties.


## Github Workflow and `grade.yml`

The template repo, which is cloned into student repos, contains a GitHub workflow file in `.github/workflows/grade.yml`. Before the assignment is released to students, you will need to edit that `grade.yml` file. At bare minimum, the steps section must be filled out to install whatever dependencies are necessary for the autograder.

Both you and students can see each job executed in the Actions section of GitHub for more detailed information in the event of a failure.

## Quickstart: Java and Python
- Describe build system integration

When a student pushes their code to Github on the branches specified in `grade.yml`, the grading job activates and proceeds through each of the steps. By default, there are three steps

- Checkout which checks out the student's code onto the image.
- The steps for installing dependencies. You should have either uncommented the default dependency steps or added your own.
- "Collect Submission and Run Grader" which runs the submission according to the autograder configuration in `pawotgrader.yml` in the solution repository.

# Simple Java project with JUnit tests

Below is an example `grade.yml` and `pawtograder.yml` for a Java project using JUnit tests. 

This `pawtograder.yml` file builds and runs the project using the default Gradle `test` task. The graded parts are JUnit tests that are part of the solution directory. Notice that the tests must be fully quantified.
```
# yaml-language-server: $schema=https://raw.githubusercontent.com/pawtograder/assignment-action/refs/tags/v3/pawtograder.schema.json

# This file is used to configure the autograding script that is run on student submissions.
# For more information about how to edit this file, see the documentation at https://docs.pawtograder.com/staff/autograding
grader: 'overlay'
build:
  preset: 'java-gradle'
  cmd: './gradlew test'
  linter:
    preset: 'checkstyle'
    policy: 'ignore'
  student_tests:
    student_impl:
      report_branch_coverage: true
      report_mutation_coverage: false
gradedParts:
  - name: Public Tests
    gradedUnits:
      - name: Valid Construction
        points: 1
        testCount: 1
        allow_partial_credit: true
        tests:
          - CreditCardPublicTest.testValidConstruction
      - name : Invalid Construction
        points: 3
        testCount: 3
        allow_partial_credit: true
        tests:
          - CreditCardPublicTest.testInvalidCreditLimitOnConstruction
          - CreditCardPublicTest.testInvalidAprOnConstruction
          - CreditCardPublicTest.testInvalidLateFeeOnConstruction
submissionFiles:
  files:
    # The default is to submit all java, arr, md, and python files.
    # You should almost definitely change this.
    - 'src/main/java/**/*.java'
  testFiles:
    - 'src/test/java/**/*.java'
```

This is the `grade.yml` for that same assignment. It is the bare minimum version that installs Java 21 Temurin on an image and runs the above autograder. 
```
name: Submit Assignment and Run Grader
permissions:
  id-token: write
  contents: read
on:
  workflow_dispatch:

  push:
    branches:
      - main

jobs:
  grade:
    name: Submit and Grade Assignment
    runs-on: khoury-course-runners
    steps:
      - name: Checkout
        id: checkout
        uses: actions/checkout@v4
        with:
          path: submission
      # The base image does NOT have Java, Python etc. So install what you need here, e.g.:
      - name: Install Java
        uses: actions/setup-java@v4
        with:
          distribution: 'temurin'
          java-version: '21'
      - name: Collect Submission and Run Grader
        uses: pawtograder/assignment-action@v3 # Update version here
        with:
          grading_server: 'https://api.pawtograder.com'
          action_ref: '${{ github.action_ref }}'
          action_repository: '${{ github.action_repository }}'

# Advanced Java project testing with mutation testing

- Create an example with mutation testing

# Python testing with custom scripts

- Create an example `pawtograder.yml` and `grade.yml` for Python testing


